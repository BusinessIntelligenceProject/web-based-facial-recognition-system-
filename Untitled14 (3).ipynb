{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03dc4110-ff90-42ad-bda0-f76fdc6e3a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (7.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.18.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: dlib in c:\\users\\tuf dash\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (19.22.99)\n",
      "C:\\famous\\aasala.jpeg\n",
      "C:\\famous\\ahenamona.jpeg\n",
      "C:\\famous\\ahend.jpeg\n",
      "C:\\famous\\amouna.jpeg\n",
      "C:\\famous\\ashendsabri.jpg\n",
      "C:\\famous\\asmonazaki1.jpeg\n",
      "C:\\famous\\asmonazaki2.jpg\n",
      "C:\\famous\\assala.jpeg\n",
      "C:\\famous\\assala1.jpeg\n",
      "C:\\famous\\assla.jpeg\n",
      "C:\\famous\\assla3.jpg\n",
      "C:\\famous\\hend.jpg\n",
      "C:\\famous\\hendsabri.jpeg\n",
      "C:\\famous\\hendsabri2.jpg\n",
      "C:\\famous\\hmona.jpeg\n",
      "C:\\famous\\images (1).jpeg\n",
      "C:\\famous\\images--I--6893.jpg\n",
      "C:\\famous\\images.jpeg\n",
      "C:\\famous\\massala2.jpeg\n",
      "C:\\famous\\moassla.jpg\n",
      "C:\\famous\\mona-zaki4.jpg\n",
      "C:\\famous\\mona.jpeg\n",
      "C:\\famous\\shend.jpeg\n",
      "C:\\famous\\xhend.jpg\n",
      "(19, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install dlib\n",
    "import dlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_data = []\n",
    "\n",
    "\n",
    "# Define the CNN model architecture\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        # Convolutional layers\n",
    "       \n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        # Flatten the feature maps\n",
    "        layers.Flatten(),\n",
    "        # Dense (fully connected) layers\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "input_shape = (100, 100, 3)  # Assuming input images are resized to 100x100 RGB\n",
    "num_classes = 3\n",
    "cnn_model = create_cnn_model(input_shape, num_classes)\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "import mysql.connector\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"C:\\\\famous\\\\\"\n",
    "\n",
    "\n",
    "# List to store flattened image vectors\n",
    "image_vectors = []\n",
    "\n",
    "# Iterate over each image file in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    # Load image\n",
    "    img_path = os.path.join(data_dir, filename)\n",
    "    print(img_path)\n",
    "    image = cv2.imread(img_path)\n",
    "    # Resize image to a fixed size (e.g., 100x100 pixels)\n",
    "    resized_image = cv2.resize(image, (100, 100))\n",
    "    # Convert image to NumPy array and normalize pixel values\n",
    "    normalized_image = resized_image.astype(np.float32) / 255.0\n",
    "    # Append image and label to the dataset\n",
    "    X_data.append(normalized_image)\n",
    "X_data = np.array(X_data)  \n",
    "y = np.array([0,1,2,1,2,1,1,0,0,0,0,2,2,2,1,0,2,1,0,0,1,1,2,2])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb88a2a-94e9-48dc-b6ca-2393bdb0a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.0723 - accuracy: 0.3158 - val_loss: 1.6638 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 1.1893 - accuracy: 0.4737 - val_loss: 1.0430 - val_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.2108 - accuracy: 0.4211 - val_loss: 1.0711 - val_accuracy: 0.2000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.0243 - accuracy: 0.4737 - val_loss: 1.2278 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.9936 - accuracy: 0.5263 - val_loss: 1.3580 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.8971 - accuracy: 0.5263 - val_loss: 1.4643 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 1.0335 - accuracy: 0.4211 - val_loss: 1.3462 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.8885 - accuracy: 0.5789 - val_loss: 1.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.8367 - accuracy: 0.5789 - val_loss: 1.2511 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.7502 - accuracy: 0.7368 - val_loss: 1.3460 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.6603 - accuracy: 0.7368 - val_loss: 1.3650 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5851 - accuracy: 0.7368 - val_loss: 1.3138 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5122 - accuracy: 0.8947 - val_loss: 1.2008 - val_accuracy: 0.4000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.3528 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 0.4000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.2876 - accuracy: 1.0000 - val_loss: 1.4398 - val_accuracy: 0.4000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.1853 - accuracy: 1.0000 - val_loss: 1.2033 - val_accuracy: 0.4000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.1973 - accuracy: 0.8421 - val_loss: 1.9372 - val_accuracy: 0.2000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.1590 - accuracy: 0.9474 - val_loss: 1.9770 - val_accuracy: 0.4000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.1148 - accuracy: 0.9474 - val_loss: 2.2559 - val_accuracy: 0.4000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2610 - accuracy: 0.8947 - val_loss: 2.0920 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = cnn_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06fe1ee1-6bd5-4569-ab2a-03718139adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "import mysql.connector\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def register_new_user(username, password):\n",
    "    # Connect to MySQL database\n",
    "    connection = mysql.connector.connect(\n",
    "        host=\"127.0.0.1\",\n",
    "        user=\"root\",\n",
    "        password=\"\",\n",
    "        database=\"test1\")\n",
    "        # Create cursor object\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    cursor.execute(\"SELECT * FROM login ORDER BY id DESC LIMIT 1\")\n",
    "    last_row = cursor.fetchone()\n",
    "    fill=[]\n",
    "    folder=\"C:/xampp/htdocs/security_project/\"\n",
    "\n",
    "    img_path =folder+last_row[3]\n",
    "    image = cv2.imread(img_path)\n",
    "       # Resize image to a fixed size (e.g., 100x100 pixels)\n",
    "    resized_image = cv2.resize(image, (100, 100))\n",
    "       # Convert image to NumPy array and normalize pixel values\n",
    "    normalized_image = resized_image.astype(np.float32) / 255.0\n",
    "       # Append image and label to the dataset\n",
    "    fill.append(normalized_image)\n",
    "    fill = np.array(fill)  \n",
    "    predictions = cnn_model.predict(fill)\n",
    "\n",
    "\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "      # Now, 'predicted_labels' will contain the predicted labels for your new data\n",
    "    print(\"Predicted Labels:\", predictions)\n",
    "    x=np.max(predictions[0])\n",
    "    if x > 0.9 :\n",
    "        x=\"recognized\"\n",
    "   \n",
    "    else:\n",
    "        x=\"not recognized\"\n",
    "    cursor.execute('''INSERT INTO verification (ID, image_comparison, password_hashed, name) VALUES (%s, %s, %s, %s)''', (last_row[0], x, last_row[4], last_row[2]))\n",
    "\n",
    "    conn.commit()\n",
    "@app.route('/security_project/Upload2.php', methods=['POST'])\n",
    "def register():\n",
    "    # Extract username and password from request data\n",
    "    username = request.form['username']\n",
    "    password = request.form['password']\n",
    "\n",
    "    # Call the register_new_user function\n",
    "    register_new_user(username, password)\n",
    "\n",
    "    # Return a response\n",
    "    return 'User registration successful'\n",
    "\n",
    "   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a53fdc7-9d9e-4232-9394-8f691ac463ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$argon2id$v=19$m=65536,t=4,p=1$Qy8vZ3hpaDZFci5mblBoSg$5kOTsEnFdtb9sACYkBSSxdSKN1FZBK7hgoiMQMWzMxg\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Connect to MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"test1\"\n",
    ")\n",
    "\n",
    "# Create cursor object\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM login ORDER BY id DESC LIMIT 1\")\n",
    "last_row = cursor.fetchone()\n",
    "\n",
    "# Print the last row\n",
    "print(last_row[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26cbda3-1d79-4c70-8891-222e974b5415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e90fa4f4-1fd0-443a-b79b-f6b5c0a9f452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n",
      "Predicted Labels: [[0.33782002 0.2942215  0.36795852]]\n"
     ]
    }
   ],
   "source": [
    "fill=[]\n",
    "folder=\"C:/xampp/htdocs/security_project/\"\n",
    "\n",
    "img_path =folder+last_row[3]\n",
    "image = cv2.imread(img_path)\n",
    "# Resize image to a fixed size (e.g., 100x100 pixels)\n",
    "resized_image = cv2.resize(image, (100, 100))\n",
    "# Convert image to NumPy array and normalize pixel values\n",
    "normalized_image = resized_image.astype(np.float32) / 255.0\n",
    "# Append image and label to the dataset\n",
    "fill.append(normalized_image)\n",
    "fill = np.array(fill)  \n",
    "predictions = cnn_model.predict(fill)\n",
    "\n",
    "# The predictions will be in the form of probabilities for each class\n",
    "# You can get the predicted class by taking the index of the maximum probability for each prediction\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Now, 'predicted_labels' will contain the predicted labels for your new data\n",
    "print(\"Predicted Labels:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950fc713-a8b9-43ee-8974-ab9ca65f90e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a89ba06-ab2e-4271-bd34-b3670b395f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36795852"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.max(predictions[0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "337ba9b0-7d77-4d24-87ce-63e6bf68cd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not recognized\n"
     ]
    }
   ],
   "source": [
    "if x > 0.9 :\n",
    "    x=\"recognized\"\n",
    "    print(\"recognized\")\n",
    "else:\n",
    "    x=\"not recognized\"\n",
    "    print(\"not recognized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a0a671e-7cb7-4e16-b8bd-26c3f59bf967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mysql.connector\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"test1\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "INSERT INTO verification (ID, image_comparison, password_hashed, name) VALUES (%s, %s, %s, %s)\n",
    "''', (last_row[0], x, last_row[4], last_row[2]))\n",
    "\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0634f5e-6802-40ca-80b1-4fea84d11ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
